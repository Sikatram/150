# CSE 150: Intro to AI - Probabilistic Reasoning and Decision Making 
# Table of Contents
* [Lecture 1](#lecture-1)
   * [What is AI?](#what-is-ai)
   * [Core Themes](#core-themes)
   * [Themes of the Course](#themes-of-the-course)
* [Lecture 2](#lecture-2)
  * [Probability in AI](#probability-in-ai)
  * [Variables and Values](#variables-and-values)
  * [Unconditional Probability](#unconditional-prior-probability)
  * [Axioms of Probability](#axioms-of-probability)
  * [Conditional Probability](#conditional-probability)
  * [Independence](#independence)
  * [More Independence](#more-independence)
  * [Conditional Independence](#conditional-independence)
  * [More Independence](#more-independence-1)
  * [Conditional Dependence](#conditional-dependence)
  * [Axioms of Conditional Probability](#axioms-of-conditional-probability)
  * [Joint Probability](#joint-probability)
  * [Marginalization](#marginalization)
  * [Product Rule Relates Joint and Conditional Probabilities](#product-rule-relates-joint-and-conditional-probabilities)
  * [Product Rule Generalization](#product-rule-generalization)
  * [Shorthand](#shorthand)
  * [Bayes' Rule](#bayes-rule)
  * [Bayes' Rule Example](#bayes-rule-example)
  * [Conditioning on background Evidence](#conditioning-on-background-evidence)
---
# Lecture 1

* ## What is AI?

  It is an extremely broad field

  * Origins of AI are over 2000 years old: [Aristotle](https://en.wikipedia.org/wiki/Aristotle) - [Deductive Reasoning](https://en.wikipedia.org/wiki/Deductive_reasoning) 
  * [Bertrand Russell](https://en.wikipedia.org/wiki/Bertrand_Russell) and [Alfred Whitehead](https://en.wikipedia.org/wiki/Alfred_North_Whitehead) published [Principia Mathematica](https://en.wikipedia.org/wiki/Principia_Mathematica)
  * Alan Turning showed that any form of mathematical reasoning can be processed by a computer
  * [Deep Blue](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)) is no longer considered AI

  CSE 150 is focused on building systems or agents that can reason about the world by using probability. Build models that leverage probability to make decisions.

  [Judea Pearl](https://en.wikipedia.org/wiki/Judea_Pearl) is known for [**Bayesian Network**](https://en.wikipedia.org/wiki/Bayesian_network)

  Before this, there were rule-based system. The Bayesian model is good for uncertainties.

  Where are these models applicable?

  Our AI needs knowledge and we need some way to represent that knowledge. The AI is trying to infer the likelihood of the disease after observing the symptoms

  Swine Flu symptoms -- fever, purple nails. multi organ failure

  Common flu cna cause fever
  Purple Nails can be done painting
  Doctors may ask questions such as, "have you been to a pig farm"

  Here we can create a bayesian network. It will be based on probabilities that give us a quantitative self-consistent way of reasoning

  A graph can show dependence and codependence

  A model for modeling sequences over time - can be used in analyzing text over speech (linear and sequential in time)

  (The first word affects the second word, the first AND second word affect the third word, the first, second, AND third word affect the fourth word)

  Common themes run through different models
* ## Core Themes
  * Probabilistic modeling of uncertainty
  * Learning as optimization
  * Knowledge as prediction
* ## Themes of the course
  * Tradeoff between power and tractability
    * Some models get way too big and take way too much time and data. A simpler smaller model may be more reasonable and practical.
  * Principles vs. heuristics
    * When are formal models like probability appropriate and when do we choose to use a heuristics
---
# Lecture 2
* ## Probability in AI

  Bayesian View of probability: a belief rather than a count of some event

  Probability Theory $==$ "How knowledge affects belief" (Poole and Mackworth)

  *Viewing probability as measuring belief (rather than frequency of events) is known as the Bayesian view of probability (as opposed to the frequentest view).*
* ## Variables and Values

  Discrete "random variables", denoted with capital letters: e.g., $X$

  Domain of possible values for a variable, denoted with lowercase letter: e.g. $\{x_1, x_2, x_3, \ldots , x_n\}$

  Example: $Weather\space W; \space \{w_1 = sunny,\space w_2 = cloudy\}$
* ## Unconditional (prior) Probability

    $P(X = x)$

    e.g., What is the probability that the weather is sunny?
    $P(W = w_1) = 0.8$
* ## Axioms of Probability

  * $P(X = x) \ge 0 \text{ : Probabilities are non-negative}$
  * $\displaystyle\sum_{i=1} ^ {n} P(X = x_i) = 1 \text{ My belief in all states sum to 1}$
  * $P(X=x_i\space or\space X=x_j)=P(X=x_i)+P(X=x_j)\space if\space x \ne x_j \text{You can independently combine the states if they're mutually exclusive}$
* ## Conditional Probability

  $P(X = x_i|Y = y_j)$
  
  "What is my belief that $X = x_i$ if I already know $Y = y_j$"

  Usually, knowing Y gives you information about X, i.e. changes your belief in X. In this case, X and Y are said to be **dependent**.

  *i.e.*

  $P(X = x_i) \ne P(X=x_i|Y=y_j)$ 

  * X and Y are dependent

  *e.g.*

  $P(W = sunny) = 0.8$

  $P(W = sunny | M = june) = 0.6$
* ## Independence

  $P(X = x_i | Y = y_i)=P(X=x_i)$
  * Sometimes knowing Y does not change your belief in X. In this case, X and Y are said to be independent.

  *e.g.*

  $P(X=w_i|Y=y_j)=P(W=w_i)$

  Example Question: For which variable Y is the above statement most likely true?

  1. Y = The Weather yesterday
  2. Y = The day of the week
  3. Y = The temperature
* ## More Independence

  Consider two students Roberto and Sabrina, who both took the same test. Define the following random variables:

  R = Roberto aced the test

  S = Sabrina aced the test


  What is the most logical relationship between $P=(R=1)$ and $P(R=1|S=1)$

  A. $P(R=1) = P(R=1|S=1)$ 

  B. $P(R=1)>P(R=1|S=1)$

  C. $P(R=1)>P(R-1|S=1)$

  *Option C. could imply that the test was easy knowing that Sabrina aced the test*
* ## Conditional Independence

  Now, let's say one gets some additional information.

  What if you also know the test was easy (variable T)?

  A. $P(R=1|T=1)=P(R=1|T=1,S=1)$ 

  B. $P(R=1|T=1)>P(R=1|T=1,S=1)$

  C. $P(R=1|T=1)>P(R-1|T=1,S=1)$

  Justification for A: if we already know the test was easy, knowing that Sabrina aced the test doesn't give us new information

  Therefore, if A is True, then R and S are conditionally independent given T.

  In other words, before we knew the test was easy, knowing S aced the test gave me some information about R.

  R and S are no longer related. They are only related through the variable T.

  So, if A is true then we have *conditional independence*. If it isn't true, then we don't have *conditional independence*.
* ## More independence

  Consider two events:
  B = A burglar breaks into your apartment
  E = An earthquake occurs

  Are these events independent or dependent? (i.e. does knowing that one happened change your belief in the other?)
* ## Conditional dependence

  *Marginal Independence*: $P(B=1)=T(B=1|E=1)=P(B=1|E=0)$

  Now consider a third event:

  A = Your alarm goes off

  Which of the following relationships best models beliefs about the world?

  1. $P(B=1|A=1)=P(B=1|A=1,E=1)$

  2. $P(B=1|A=1)>P(B=1|A=1,E=1)$

  3. $P(B=1|A=1)<P(B=1|A=1,E=1)$

  Option 2 makes the most sense here. This a phenomena known as *Explaining Away*

  If the alarm is going off, you need an explanation. B and E are conditionally dependent

  All options can be justified in some twisted world, however we are going off of intuition.

  Marginal means 'without the condition'
* ## Axioms of Conditional Probability

  Which of the following axioms hold for conditional probabilities?

  A. $P(X=x_i|Y=y_j)\ge 0$

  B. $\displaystyle\sum_{i}P(X=x_i|Y=y_j)=1$

  C. $\displaystyle\sum_{j}P(X=x_i|Y=y_j)=1$

  D. A and B only

  E. A, B and C

  Option D is correct because probabilities must be greater than or equal to zero AND adding all the probabilities of X have to sum to one
* ## Joint Probability

  $P(X=x_i,Y=y_j)$

  Joint Probability is a probability over two or more variables

  Unlike conditional probability, we don't know the probability of either of these variables

  i.e. What is my belief that $X=x_i$ **and that** $Y=y_j$"

  $T\in \{t_1=hot,t_2=cool\}$

  $W\in\{w_1=sunny,w_2=cloudy\}$

  ||T = hot|T = cool|
  |-|-|-|
  |*W* = sunny|0.5|0.3|
  |*W* = cloudy| 0.05|0.15|

  The values in the table will sum to one because they are the total state of the world
* ## Marginalization

  You can go from a joint probability to a marginal probability through marginalization

  $P(X=x_i)=\displaystyle\sum_{j}P(X=x_i,Y=y_j)$
* ## Product Rule: relates joint and conditional probabilities

  $\text{for all i,j }P(X=x_i|Y=y_j)=\dfrac{P(X=x_i,Y=y_j)}{P(Y=y_i)}$

  The product rule relates joint probabilities to conditional probabilities

  e.g. How do I determine the probability of when it's Sunny? I sum up the probabilities along the columns
  |||
  |-|-|
  |*W* = sunny|0.8|
  |*W* = cloudy|0.2|

  Another Permutation:

  $P(X|Y)P(Y) = P(X,Y)$

  i.e. we can go between this marginal table and joint table by calculating this conditional probability
* ## Product Rule Generalization

  $P(A=a_i,B=b_j,C=c_k,D=d_l,\ldots)=P(A=a_i)P(B=b_j|A=a_i)P(C=c_k|A=a_i,B=b_j)\ldots$
* ## Shorthand

  Implied Universality:

  $P(X,Y)=P(X|Y)P(Y)=P(Y|X)P(X)$

  Implied Assignment:

  $P(x,y,z)=P(X=x,Y=y,Z=z)$
* ## Bayes' Rule

  $P(X|Y)=\dfrac{P(Y|X)P(X)}{P(Y)}$

  Bayes' Rule can be derived from the Product Rule

  $P(X,Y)=P(X|Y)P(Y)=P(Y|X)P(X)$

  $\dfrac{P(X|Y)P(Y)}{P(Y)}=\dfrac{P(Y|X)P(X)}{P(Y)}$

  $\dfrac{P(X|Y)\cancel{P(Y)}}{\cancel{P(Y)}}=\dfrac{P(Y|X)P(X)}{P(Y)}$

  $P(X|Y)=\dfrac{P(Y|X)P(X)}{P(Y)}$
* ## Bayes' Rule example
  * Let's assume breast cancer affect 1% of all patients
  * When a patient has cancer, a mammogram test comes back positive 805 of the time (true positive)
  * When a patient does not have cancer, a mammogram test comes back positive 9% of the time (false positive)
  * A patient has a positive mammogram test. What is the probability the patient has cancer?

  Our variables will be:

  $C\in\{c_0=\text{no cancer}, c_1=\text{cancer}\}$
  
  $T\in\{t_0=\text{test negative}, t_1=\text{test positive}\}$

  |Known Probabilities|
  |-|
  |$P(C=c_1)=0.01$|
  |$P(C=c_0)=0.99$|
  |$P(T=t_1\|C=c_0)=0.09$|
  |$P(T=t_0\|C=c_0)=0.91$|
  |$P(T=t_1\|C=c_1)=0.80$|
  |$P(T=t_0\|C=c_1)=0.20$|

  $P(C=c_1|T=t_1)\text{ i.e. We want to know the probability a patient has cancer, knowing that the patient had a positive test}$
  
  When you see a conditional that is opposite of what you know, Bayes' Rule is almost always the right rule to apply

  $P(C=c_1|T=t_1) = \dfrac{P(T|C)P(C)}{P(T)}$

  We know the numerator values from our table

  $P(C=c_1|T=t_1) = \dfrac{0.80\times0.01}{P(T)}$

  The denominator in Bayes' rule is usually never simple to calculate

  Here, we will want to introduce marginalization

  $P(t_1) = P(t_1,c_1) + P(t_1,c_0)$

  Here, we introduced cancer so that we can get this into a form that we can reason about it

  Looking at one of our unknowns, $P(t_1,c_1)$, we don't know this yet

  To calculate this, we can apply the product rule

  $P(t_1,c_1) = P(t_1|c_1)P(c_1)$

  $P(t_1,c_1) = 0.80 \times 0.01$
  
  $P(t_1,c_1) = 0.008$

  $P(t_1) = 0.008 + P(t_1,c_0)$

  Now lets solve for $P(t_1,c_0)$ using the product rule

  $P(t_1,c_0)= P(t_1|c_0)P(c_0)$

  $P(t_1,c_0)= 0.09\times0.99$

  $P(t_1,c_0)= 0.0891$

  $P(t_1) = 0.008 + 0.0891$

  $P(t_1) = 0.0971$

  Now we can go back to our original equation

  $P(C=c_1|T=t_1) = \dfrac{0.80\times0.01}{0.0971}$

  $P(C=c_1|T=t_1) = 0.0824$
* ## Conditioning on Background Evidence
  * $\text{Product rule (conditional): }P(X,Y|E)=P(Y|X,E)P(X|E)$
  
  * $\text{Bayes' rule (conditional): } P(X|Y,E)=\dfrac{P(Y|X,E)P(X|E)}{P(Y|E)}$

  * $\text{Marginalization (conditional): } P(X|E)=\displaystyle\sum_{y}P(X,Y = y|E)$

  Product rule without background evidence: $P(X,Y)=P(Y|X)P(X)$
  * Claim: $P(X,Y|E)=P(Y|X,E)P(X|E)$

  Prove the conditional version of the product rule

  All the rules have conditional versions

  **Proof**:

  $P(X,Y|E)=P(Y|X,E)P(X|E)$

  Needs to be completed
---
